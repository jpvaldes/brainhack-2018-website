<html>
<head>
  <title>Project Ideas</title>
  <meta name="save_as" content="projects.html" />
  <meta name="url" content="projects.html" />
</head>
<body>
  <header id='project-landing' class='card'>
    <div class="wrapper">
      <div class='blurb'>
        <h1>Project <strong>Ideas</strong></h1>
        <p>For now these are only ideas. You can help make them happen.</p>
      </div>
    </div>
  </header>
  <div class='projects'>
<!-- Available info icons:
     <li class='icon-project'><a href='#'>Project Page</a></li>
     <li class='icon-people'>Name, Another Name, So Popular</li>
     <li class='icon-contact'>email@address.com</li>
     <li class='icon-link'><a href='#'>a link</a></li>
-->
    <section class='pitch'>
      <header>
        <img src='/theme/img/pitch_datalad.png' />
        <h2>Research Data Management with DataLad</h2>
      </header>
      <ul class='info'>
        <li class='icon-people'>Michael Hanke</li>
        <li class='icon-contact'>michael.hanke@gmail.com</li>
        <li class='icon-link'><a href='http://datalad.org'>datalad.org</a></li>
      </ul>
      <p>Research data management is crucial for projects of any size. This
      <span class='tutorial'>tutorial</span> introduces you to DataLad, an
      open-source solution for decentralized data management that is build atop
      Git. DataLad's features make it a perfect fit for tracking your research
      output, whether it's produced on your laptop or in the "cloud". DataLad
      helps you get ready for open-science from the very start.</p>
    </section>

    <section class='pitch'>
      <header>
        <img src='/theme/img/pitch_pymvpa.png' />
        <h2>BIDS-app-Based Searchlight Analysis Pipeline</h2>
      </header>
      <ul class='info'>
        <li class='icon-people'>Michael Hanke</li>
        <li class='icon-contact'>michael.hanke@gmail.com</li>
        <li class='icon-link'><a href='http://bids-apps.neuroimaging.io'>BIDS-app</a></li>
        <li class='icon-link'><a href='http://www.pymvpa.org'>PyMVPA</a></li>
      </ul>
      <p>Decoding analysis using a traveling "searchlight" are a widely used
      approach to map the availability of a given signal, and can also be used
      for a representational similarity analysis (RSA). This
      <span class='project'>project</span> aims to produce a BIDS-app for a
      PyMVPA-based searchlight analysis for decoding and RSA.</p>
    </section>

    <section class='pitch'>
      <header>
        <img src='/theme/img/pitch_ph_clover.jpg' />
        <h2>Basics of Image Reconstruction: From Raw Data to the Image</h2>
      </header>
      <ul class='info'>
        <li class='icon-people'>Falk Lüsebrink</li>
        <li class='icon-contact'>falk.luesebrink@ovgu.de</li>
      </ul>
      <p>In this <span class='project'>project</span>, a basic reconstruction
      pipeline is to be developed for Cartesian sampled gradient echo data. This
      includes reading raw data, k space filtering, data synthesis in case of
      partial Fourier, coil combination (sum of squares and adaptive
      combination) and writing of image files. The aim is to reconstruct image
      with at least the quality of the vendors.</p>
    </section>

    <section class='pitch'>
      <header>
        <img src='/theme/img/pitch_nipype.png' />
        <h2>Containerized Nipype Pipelines on the Cluster</h2>
      </header>
      <ul class='info'>
        <li class='icon-people'>José P. Valdés-Herrera</li>
        <li class='icon-contact'>jose.valdes@dzne.de</li>
        <li class='icon-link'><a href='http://nipype.readthedocs.io/'>Nipype</a></li>
        <li class='icon-link'><a href='https://www.docker.com'>Docker</a></li>
        <li class='icon-link'><a href='http://singularity.lbl.gov'>Singularity</a></li>
      </ul>
      <p>This <span class='project'>project</span> proposes taking custom or
      already available pipelines developed using Nipype, package them in a
      container using Docker or Singularity, and integrate them with cluster
      software (SLURM, SGE, Condor). The aim is to automate the process of
      taking those pipelines to a cluster as much as possible, either by
      developing scripts or extending Nipype's functionality.</p>
    </section>

    <section class='pitch'>
      <header>
        <img src='/theme/img/pitch_dask.png' />
        <h2>Machine Learning with Dask and Neuroimaging Data</h2>
      </header>
      <ul class='info'>
        <li class='icon-people'>José P. Valdés-Herrera</li>
        <li class='icon-contact'>jose.valdes@dzne.de</li>
        <li class='icon-link'><a href='https://dask.pydata.org/'>Dask</a></li>
      </ul>
      <p>The aim of this <span class='project'>project</span> is to analyse
      large neuroimaging datasets &mdash; that do not fit in memory &mdash; even
      without access to powerful machines or clusters. To achieve this, we can
      use machine learning libraries (Nilearn, PyMVPA, scikit-learn) together
      with a library like Dask. During the event, the goal is to integrate
      these tools, pick a large dataset, and analyse it on "modest" hardware
      (e.g. a laptop).</p>
    </section>

    <section class='pitch'>
      <header>
        <img src='/theme/img/pitch_ph_limes.png' />
        <h2>Motor Imagery Classification with Deep Neural Networks</h2>
      </header>
      <ul class='info'>
        <li class='icon-people'>JiaHua Xu</li>
        <li class='icon-contact'>jiahua.xu@med.ovgu.de</li>
        <li class='icon-link'><a href='http://www.bbci.de/competition/iv/#dataset'>Datasets</a></li>
        <li class='icon-link'><a href='https://www.martinos.org/mne/stable/index.html'>MNE</a></li>
        <li class='icon-link'><a href='http://scikit-learn.org/stable/'>scikit-learn</a></li>
      </ul>
      <p>Motor imagery represents frequency phenomenon of Event-Related
      Desynchronization (ERD) and Event-Related Synchronization (ERS) in the
      motor cortex. In this <span class='tutorial'>tutorial</span>, you will
      jointly train a logistic regression and a deep neural network combined
      model (Deep&amp;Wide Learning) to evaluate the performance on four classes
      of motor imagery data.</p>
    </section>

    <section class='pitch'>
      <header>
        <img src='/theme/img/pitch_ph_paint.png' />
        <h2>Brain Network Analysis Pipelines in Neuroimaging Data</h2>
      </header>
      <ul class='info'>
        <li class='icon-people'>JiaHua Xu</li>
        <li class='icon-contact'>jiahua.xu@med.ovgu.de</li>
        <li class='icon-link'><a href='http://www.fieldtriptoolbox.org/'>FieldTrip</a></li>
        <li class='icon-link'><a href='https://www.martinos.org/mne/stable/index.html'>MNE</a></li>
        <li class='icon-link'><a href='https://sites.google.com/site/bctnet/'>Brain Connectivity Toolbox</a></li>
      </ul>
      <p>This <span class='project'>project</span> will focus on the pipelines
      of brain network analysis when using EEG data with different kinds of
      graphics measures, from mathematics to practical. The aim is to help
      visualize the brain dynamic connectivity changes and understand the
      network structures of brain activities in a different perspective.</p>
    </section>

    <section class='pitch'>
      <header>
        <img src='/theme/img/pitch_brain.png' />
        <h2>Highest Resolution T1-weighted In Vivo Human Brain MRI Data</h2>
      </header>
      <ul class='info'>
        <li class='icon-people'>Falk Lüsebrink</li>
        <li class='icon-contact'>falk.luesebrink@ovgu.de</li>
        <li class='icon-link'><a href='http://www.nature.com/articles/sdata201732'>publication</a></li>
      </ul>
      <p>In this <span class='tutorial'>tutorial</span>, the so far highest
      resolution T1-weighted in vivo human brain MRI data will be presented.
      Details will be given on what the entire data set consists of, how it was
      acquired, how it will be extended in the near future, and what potential
      use cases of it are. Besides simply showing some astonishing images of the
      brain.</p>
    </section>

    <section class='pitch'>
      <header>
        <img src='/theme/img/pitch_ph_dots.png' />
        <h2>How to Open Data (at OvGU)</h2>
      </header>
      <ul class='info'>
        <li class='icon-people'>Falk Lüsebrink</li>
        <li class='icon-contact'>falk.luesebrink@ovgu.de</li>
      </ul>
      <p>Sharing your data openly is fantastic and may be beneficial for
      everyone. However, to improve visibility and enable citeability, data has
      to be provided with a digital object identifier (DOI). This <span
      class='tutorial'>tutorial</span> will guide you through the steps to
      successfully apply for a DOI at the OvGU university library. Starting from
      the application itself, how and where to host data, and the regulations.
      Non-OvGU-members will learn how your institute is able to provide
      DOIs.</p>
    </section>

    <section class='pitch'>
      <header>
        <img src='/theme/img/pitch_audio.png' />
        <h2>Hear What I Hear: Reconstructing the Music in Our Heads</h2>
      </header>
      <ul class='info'>
        <li class='icon-people'>Andrew Curran</li>
        <li class='icon-contact'>andrew.curran@med.ovgu.de</li>
        <li class='icon-link'><a href='http://www.eneuro.org/content/early/2018/01/29/ENEURO.0358-17.2018'>Visual Image Reconstruction</a></li>
      </ul>
      <p>Recently, research groups have shown that it is possible to read images
      from a person's brain as they are seen using both fMRI and EEG through
      machine learning strategies. These strategies have however not yet been
      applied to auditory stimuli. It should theoretically also be possible to
      record imagined visual or auditory perceptions. This
      <span class='project'>project</span> aims to utilize the same principles
      to extract simple musical details through EEG, and potentially even
      imagined music.</p>
    </section>
  </div>
</body>
</html>
