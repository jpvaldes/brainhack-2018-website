<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="author" content="BrainHack Magdeburg" />
  <title>BrainHack Magdeburg &ndash; Project Ideas</title>

  <!-- once upon a time, favicons were a simple folk; but then they grew to be greedy... -->
  <link rel="apple-touch-icon" sizes="180x180" href="./apple-touch-icon.png?v=E6j37mrY2e">
  <link rel="icon" type="image/png" sizes="32x32" href="./favicon-32x32.png?v=E6j37mrY2e">
  <link rel="icon" type="image/png" sizes="16x16" href="./favicon-16x16.png?v=E6j37mrY2e">
  <link rel="manifest" href="./site.webmanifest?v=E6j37mrY2e">
  <link rel="mask-icon" href="./safari-pinned-tab.svg?v=E6j37mrY2e" color="#ff9e0d">
  <link rel="shortcut icon" href="./favicon.ico?v=E6j37mrY2e">
  <meta name="apple-mobile-web-app-title" content="BrainHack Magdeburg">
  <meta name="application-name" content="BrainHack Magdeburg">
  <meta name="msapplication-TileColor" content="#ff9e0d">
  <meta name="theme-color" content="#ff9e0d">

  <link rel="stylesheet" type="text/css" href="./theme/css/style.css">
</head>
<body>
  <main>
  <nav class='card'>
    <ul>
      <li><a href="./index.html" >home</a></li>
      <li><a href="./projects.html"  class='active' >projects</a></li>
      <li><a href="./details.html" >details</a></li>
    </ul>
  </nav>

  
  <header id="project-landing" class="card">
    <div class="wrapper">
      <div class="blurb">
        <h1>Project <strong>Ideas</strong></h1>
        <p>For now these are only ideas. You can help make them happen.</p>
      </div>
    </div>
  </header>
  <div class="projects">
<!-- Available info icons:
     <li class='icon-project'><a href='#'>Project Page</a></li>
     <li class='icon-people'>Name, Another Name, So Popular</li>
     <li class='icon-contact'>email@address.com</li>
     <li class='icon-link'><a href='#'>a link</a></li>
-->
    <section class="pitch">
      <header>
        <img src="/theme/img/pitch_datalad.png" />
        <h2>Research Data Management with DataLad</h2>
      </header>
      <ul class="info">
        <li class="icon-people">Michael Hanke</li>
        <li class="icon-contact">michael.hanke@gmail.com</li>
        <li class="icon-link"><a href="http://datalad.org">datalad.org</a></li>
      </ul>
      <p>Research data management is crucial for projects of any size. This
      tutorial introduces you to DataLad, an open-source solution for
      decentralized data management that is build atop Git. DataLad's features
      make it a perfect fit for tracking your research output, whether it's
      produced on your laptop or in the "cloud". DataLad helps you get ready for
      open-science from the very start.</p>
    </section>

    <section class="pitch">
      <header>
        <img src="/theme/img/pitch_pymvpa.png" />
        <h2>BIDS-app-Based Searchlight Analysis Pipeline</h2>
      </header>
      <ul class="info">
        <li class="icon-people">Michael Hanke</li>
        <li class="icon-contact">michael.hanke@gmail.com</li>
        <li class="icon-link"><a href="http://bids-apps.neuroimaging.io">BIDS-app</a></li>
        <li class="icon-link"><a href="http://www.pymvpa.org">PyMVPA</a></li>
      </ul>
      <p>Decoding analysis using a traveling "searchlight" are a widely used
      approach to map the availability of a given signal, and can also be used
      for a representational similarity analysis (RSA). This project aims to
      produce a BIDS-app for a PyMVPA-based searchlight analysis for decoding
      and RSA.</p>
    </section>

    <section class="pitch">
      <header>
        <img src="/theme/img/pitch_ph_clover.jpg" />
        <h2>Basics of Image Reconstruction: From Raw Data to the Image</h2>
      </header>
      <ul class="info">
        <li class="icon-people">Falk Lüsebrink</li>
        <li class="icon-contact">falk.luesebrink@ovgu.de</li>
      </ul>
      <p>In this project a basic reconstruction pipeline is to be developed for
      Cartesian sampled gradient echo data. This includes reading raw data, k
      space filtering, data synthesis in case of partial Fourier, coil
      combination (sum of squares and adaptive combination) and writing of image
      files. The aim is to reconstruct image with at least the quality of the
      vendors.</p>
    </section>

    <section class="pitch">
      <header>
        <img src="/theme/img/pitch_nipype.png" />
        <h2>Containerized Nipype Pipelines on the Cluster</h2>
      </header>
      <ul class="info">
        <li class="icon-people">José P. Valdés-Herrera</li>
        <li class="icon-contact">jose.valdes@dzne.de</li>
        <li class="icon-link"><a href="http://nipype.readthedocs.io/">Nipype</a></li>
        <li class="icon-link"><a href="https://www.docker.com">Docker</a></li>
        <li class="icon-link"><a href="http://singularity.lbl.gov">Singularity</a></li>
      </ul>
      <p>This project proposes taking custom or already available pipelines
      developed using Nipype, package them in a container using Docker or
      Singularity, and integrate them with cluster software (SLURM, SGE,
      Condor). The aim is to automate the process of taking those pipelines to a
      cluster as much as possible, either by developing scripts or extending
      Nipype's functionality.</p>
    </section>

    <section class="pitch">
      <header>
        <img src="/theme/img/pitch_dask.png" />
        <h2>Machine Learning with Dask and Neuroimaging Data</h2>
      </header>
      <ul class="info">
        <li class="icon-people">José P. Valdés-Herrera</li>
        <li class="icon-contact">jose.valdes@dzne.de</li>
        <li class="icon-link"><a href="https://dask.pydata.org/">Dask</a></li>
      </ul>
      <p>The aim of this project is to analyse large neuroimaging datasets, that
      do not fit in memory, even without access to powerful machines or
      clusters. To achieve this, we can use machine learning libraries
      (Nilearn, PyMVPA, scikit-learn) together with a library like Dask.
      During the event, the goal is to integrate these tools, pick a large
      dataset, and analyse it on "modest" hardware (e.g. a laptop).</p>
    </section>

    <section class="pitch">
      <header>
        <img src="/theme/img/pitch_ph_paint.png" />
        <h2>Brain Network Analysis Pipelines in Neuroimaging Data</h2>
      </header>
      <ul class="info">
        <li class="icon-people">JiaHua Xu</li>
        <li class="icon-contact">jiahua.xu@med.ovgu.de</li>
        <li class="icon-link"><a href="http://www.fieldtriptoolbox.org/">FieldTrip</a></li>
        <li class="icon-link"><a href="https://www.martinos.org/mne/stable/index.html">MNE</a></li>
        <li class="icon-link"><a href="https://sites.google.com/site/bctnet/">Brain Connectivity Toolbox</a></li>
      </ul>
      <p>This project will focus on the pipelines of brain network analysis when
      using EEG data with different kinds of graphics measures, from mathematics
      to practical. The aim is to help visualize the brain dynamic connectivity
      changes and understand the network structures of brain activities in a
      different perspective.</p>
    </section>

    <section class="pitch">
      <header>
        <img src="/theme/img/pitch_ph_limes.png" />
        <h2>Motor Imagery Classification with Deep Neural Networks</h2>
      </header>
      <ul class="info">
        <li class="icon-people">JiaHua Xu</li>
        <li class="icon-contact">jiahua.xu@med.ovgu.de</li>
        <li class="icon-link"><a href="http://www.bbci.de/competition/iv/#dataset">Datasets</a></li>
        <li class="icon-link"><a href="https://www.martinos.org/mne/stable/index.html">MNE</a></li>
        <li class="icon-link"><a href="http://scikit-learn.org/stable/">scikit-learn</a></li>
      </ul>
      <p>Motor imagery represents frequency phenomenon of Event-Related
      Desynchronization (ERD) and Event-Related Synchronization (ERS) in the
      motor cortex. In this tutorial, you will jointly train a logistic
      regression and a deep neural network combined model (Deep&Wide; Learning)
      to evaluate the performance on four classes of motor imagery data.</p>
    </section>

    <section class="pitch">
      <header>
        <img src="/theme/img/pitch_brain.png" />
        <h2>Highest Resolution T1-weighted In Vivo Human Brain MRI Data</h2>
      </header>
      <ul class="info">
        <li class="icon-people">Falk Lüsebrink</li>
        <li class="icon-contact">falk.luesebrink@ovgu.de</li>
        <li class="icon-link"><a href="http://www.nature.com/articles/sdata201732">publication</a></li>
      </ul>
      <p>In this project, the so far highest resolution T1-weighted in vivo
      human brain MRI data will be presented. Details will be given on what the
      entire data set consists of, how it was acquired, how it will be extended
      in the near future, and what potential use cases of it are. Besides simply
      showing some astonishing images of the brain.</p>
    </section>

    <section class="pitch">
      <header>
        <img src="/theme/img/pitch_ph_dots.png" />
        <h2>How to Open Data (at OvGU)</h2>
      </header>
      <ul class="info">
        <li class="icon-people">Falk Lüsebrink</li>
        <li class="icon-contact">falk.luesebrink@ovgu.de</li>
      </ul>
      <p>Sharing your data openly is fantastic and may be beneficial for
      everyone. However, to improve visibility and enable citeability, data has
      to be provided with a digital object identifier (DOI). This tutorial will
      guide you through the steps to successfully apply for a DOI at the OvGU
      university library. Starting from the application itself, how and where to
      host data, and the regulations. Non-OvGU-members will learn how your
      institute is able to provide DOIs.</p>
    </section>

    <section class="pitch">
      <header>
        <img src="/theme/img/pitch_audio.png" />
        <h2>Hear What I Hear: Reconstructing the Music in Our Heads</h2>
      </header>
      <ul class="info">
        <li class="icon-people">Andrew Curran</li>
        <li class="icon-contact">andrew.curran@med.ovgu.de</li>
        <li class="icon-link"><a href="http://www.eneuro.org/content/early/2018/01/29/ENEURO.0358-17.2018">Visual Image Reconstruction</a></li>
      </ul>
      <p>Recently, research groups have shown that it is possible to read images
      from a person's brain as they are seen using both fMRI and EEG through
      machine learning strategies. These strategies have however not yet been
      applied to auditory stimuli. It should theoretically also be possible to
      record imagined visual or auditory perceptions. This project aims to
      utilize the same principles to extract simple musical details through EEG,
      and potentially even imagined music.</p>
    </section>
  </div>



    <footer class='card'>
      <p>content licensed <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">cc-by-sa</a>
        <span class='break'>—</span> &copy;2018 BrainHack Magdeburg <span class='break'>—</span>
        unless <a rel="license" href='./copyright.html'>indicated otherwise</a>
      </p>
    </footer>

  </main>
</body>
</html>